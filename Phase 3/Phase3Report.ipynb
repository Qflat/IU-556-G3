{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8f9750-5e9a-4f66-b654-e81bfc078dfe",
   "metadata": {},
   "source": [
    "**Project Title**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7631066-2f10-4c32-aa5c-c2c705fbe938",
   "metadata": {},
   "source": [
    "Home Credit Default Risk (HCDR) Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6a4be-95e0-4d4a-bef7-ded3bde4e08f",
   "metadata": {},
   "source": [
    "**Team and Phase Leader Plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b309356-9fd6-4c99-8b84-56c7e98e4b83",
   "metadata": {},
   "source": [
    "*Team Name*: FP_Group_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978d34c-faf5-469c-ba78-9a6de524b8d0",
   "metadata": {},
   "source": [
    "*Phase 3 Leader*: Jaden Costa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb432bb8-80c4-4713-aefd-d697a705f0be",
   "metadata": {},
   "source": [
    "|Team Members|\n",
    "|------------|\n",
    "|Alicia Aaholm|\n",
    "|Nicholas Chappell|\n",
    "|Jaden Costa|\n",
    "|Katia Torres Sanchez|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78628fcc-e063-4c9f-b36d-4a43994e912b",
   "metadata": {},
   "source": [
    "**Credit Assignment Plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad201e-f651-41ae-8989-7b055547d791",
   "metadata": {},
   "source": [
    "|Phase|Task|Person Responsible|Estimated Person-Hrs|\n",
    "|-----|----|-------------------|--------------------|\n",
    "|Phase 3|Jaden will conduct another round of feature engineering.|Jaden|2 hr|\n",
    "|Phase 3|Nicholas will conduct any additional hyperparameter tuning.|Nicholas|2 hr|\n",
    "|Phase 3|Alicia will decide on any additional feature selections to be added as well as ensemble methods.|Alicia |1 hr|\n",
    "|Phase 3|The team will complete a project update, which will include a 2 minute video presentation, a slide deck, and a Jupyter notebook that will be submitted to the Canvas discussion portal |All |2 hrs|\n",
    "|Phase 3|Katia will write up the report following the structure set by the rubric on Canvas for assignment Phase 3.| Katia| 1 hr|\n",
    "|Phase 3|Katia will upload the slide deck and Jupyter notebook to Canvas.| Katia| 10 mins|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92871375-41ab-490d-9559-e4184d97a1e4",
   "metadata": {},
   "source": [
    "**Project Abstract**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7403ca-a4ab-48c5-9672-11a318e9b96b",
   "metadata": {},
   "source": [
    "During Phase 3 of the HCDR Project, the team is focused on enhancing the models designed in Phase 2. The problems being tackled included models that are not performing at a optimal level, based on metrics such as F1 score and accuracy. The models produced in Phase 2 are not ideal for predicting which clients will default on a home credit loan. Thus, the goal of Phase 3 is to produce better predictions by performing additional feature engineering and hyperparameter tuning. In Phase 3, the team also performed feature selection based on a analysis of the importance of the features. An ensemble method was also used to enhance the model pipelines. The ensemble model has had the best performance. It is better than the logistic regression, tuned random forest, and random forest pipelines. The best score our team has produced is the 0.762 from the ensemble pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86a9c6-6221-4d65-b848-cf791fc7f215",
   "metadata": {},
   "source": [
    "**Introduction/Project Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac844b4d-7dde-4e19-a184-62877a506e0a",
   "metadata": {},
   "source": [
    "In Phase 3, the tasks to be tackled include feature engineering using recency, frequency, and monetary value fatures. There was also hyperparameter tuning and feature selction performed. The final task was to use ensemble methods to improve the model pipelines from Phase 2. The data used was from the bureau dataset and application_train dataset, which is further explained in the Data Lineage section of this report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04ae59-4d5a-4c97-98ab-efc007c1a18b",
   "metadata": {},
   "source": [
    "**Data Lineage**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149de0-a59c-42b1-9d06-c35d8c26ebb8",
   "metadata": {},
   "source": [
    "We continued to use the data sets that are provided by the HCDR Kaggle Competition file. During Phase 3, there was a focus on the application_train and bureau datasets. Below is a description of the datasets.\n",
    "- Application Data: Includes the majority of information regarding clients, such as the gender, income, family status, education, number of children, amount of income, and whether the client owns a car or not. The application data has split the main training data from the testing data.\n",
    "- Bureau Data: This dataset contains data on clientsâ€™ credit history.\n",
    "\n",
    "The datasets were merged in Phase 3 to perform the required tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1dd05a-2b76-4df9-bde5-977902f768a1",
   "metadata": {},
   "source": [
    "*Workflow of Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd8c8b-e76d-400f-ad56-38dd602498a6",
   "metadata": {},
   "source": [
    "The following image is a workflow of all the datasets. However, the team focused on application_train.csv and bureau.csv datasets to create the recency, frequency, and monetary features. The recency feature captured the most recent loan, or max of the DAYS_CREDIT variable. The frequency feature captured the number of past loans. The monetary feature captured total past credit. Any missing values for these features had a impute missing value performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaaf4e9-aaea-44af-bfc9-90d033502234",
   "metadata": {},
   "source": [
    "![image](MLDataImage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b68916-3b1d-466a-9b31-dee26b62f4a0",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc1beb-a124-4365-a634-5f878eea2e44",
   "metadata": {},
   "source": [
    "Feature engineering was performed to improve the predictions the models were producing. It is important to perform feature engineering to provide the training data with additional features that can be used to optimize the model. Appropriate feature engineering can provide a positive impact to the model. However, the features selected must be correlated to the loan default target variable to have a significant impact on the model. In Phase 3, the team added features for recency, frequency, and monetary, as stated in the data lineage section. This approach was chosen becasue RFM metrics tend to be vital indicators of how a customer may behave. As mentioned in the Canvas assignment, each feature can disclose a customer's lifetime value, retention, or engagement. All of which are important to consider when reviewing loan applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768d7fa-0ebf-4af8-8d38-69c2071fcfcb",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076279f-73ff-4135-bb4c-49eeaf2b7ea3",
   "metadata": {},
   "source": [
    "After completing feature engineering and selecting the Random Forest classifer as the base model, hyperparameter tuning was performed to identify the optimal parameter configuration. The goal of hyperparameter tuning was to imporve the model's generalization performance by systematically exploring combinations of key Random Forest parameters, such as the number of trees, the tree depth, and minimum sample requirements for splitting the nodes.\n",
    "\n",
    "RandomizedSearchCV was chosen for tuning. This method randomly samples a defined number of hyperparameter combinations from the search space. It provides a balance between computational efficiency and model performance, which is important since the parameter space is larage. The RandomizedSearchCV was configured to evaluate 10 random combinations using 3 fold cross validation. The ROC-AUC is used as the scoring metric.\n",
    "\n",
    "The tuning process explored variations in n_estimators, max_depth, min_samples_split, and min_samples_leaf. The best performing configuration was selected based on the highest average ROC-AUC score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef2949-afd7-489d-a454-aa552a18b01c",
   "metadata": {},
   "source": [
    "**Modeling Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80013c43-d51f-4e4c-8761-c4f07f0968e1",
   "metadata": {},
   "source": [
    "Our modeling pipeline combined feature engineering, model tuning, and ensemble learning to improve loan repayment prediction. We began by creating Recency, Frequency, and Monetary features from the bureau dataset, then merged them into the application data to expand the behavioral signal available to the model. After preprocessing and imputing missing values, we tuned a Random Forest model using RandomizedSearchCV to explore variations in tree count, depth, and split thresholds. This process allowed us to evaluate multiple configurations through cross-validation and select a more stable model. We then introduced a soft-voting ensemble that combined Logistic Regression with the tuned Random Forest to capture both linear patterns and more complex nonlinear relationships. Finally, we reviewed feature importance scores to understand which inputs had the strongest influence on predictions and to validate the usefulness of the engineered RFM features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8cb10-fe00-49ef-b50b-e9d217dfc4e4",
   "metadata": {},
   "source": [
    "**Results and Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682df4e-4bfa-4538-95ce-e2b456158495",
   "metadata": {},
   "source": [
    "The best model during Phase 3 was the ensemble model. The hyperparameter used was soft voting. It produced a 0.762 ROC AUC score, which is also higher than the ROC_AUC scores produced during Phase 2. The two lowest performing models used the default hyperparameters. Although the tuned random forest model had the best single model, the ensemble model had a better overall ROC_AUC score. The RFM features lifted the AUC_ROC by over 0.015, showcasing that it did impact the model in a positive manner. Frequency was the top feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab3b02-6c71-44f6-b0a6-3c8f686a29df",
   "metadata": {},
   "source": [
    "*Visualization of the Model Pipelines Experiment Log*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b205f7-b126-4668-9812-cd8d45d70e72",
   "metadata": {},
   "source": [
    "![phase3.png](phase3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74cab1-35b5-4d43-8813-3af2eb01edaa",
   "metadata": {},
   "source": [
    "*Gap Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b04455-de20-4e66-83b0-d38dbf70658c",
   "metadata": {},
   "source": [
    "Although these results represent a meaningful improvement over the baseline Logistic Regression model, they still fall short of the leaderboard benchmark of 0.795. This gap suggests that the pipeline may benefit from more expressive models or richer feature sets, especially around installment and credit-use behavior. Some likely improvements can be gradient boosting and installment features. Ensemble methods appears to be working well. Logistic regression and default hyperparameters had the lowest ROC AUC, so hyperparameter tuning has performed well enough to improve our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440bfaa-c793-4349-86f5-22c9b5640938",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685945a-e901-4b52-8640-f76c8abd17e0",
   "metadata": {},
   "source": [
    "This project focused on building an effective machine learning pipeline to predict loan repayment outcomes using the HCDR dataset. Our goal was to test whether custom feature engineering and systematic model tuning could improve predictive accuracy. The results support this hypothesis: RFM features added valuable behavioral insight, and the tuned models consistently outperformed simpler baselines. These findings highlight the importance of feature quality and model selection when working with credit-risk data. While our current best model performs well, we see opportunities for further improvement through gradient boosting methods, deeper hyperparameter searches, and expanded behavioral features. In future work, we will refine these approaches and prepare the model for a more production-ready deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
